{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\renewcommand{\\vec}[1]{\\mathbf{#1}}$$\n",
    "Matrix norms are an extension of [vector norms](https://aaronschlegel.me/vector-norms-inequalities-python.html) to matrices and are used to define a measure of distance on the space of a matrix. More specifically, a matrix norm is defined as a function $f: \\mathbb{R}^{m \\times n} \\rightarrow \\mathbb{R}$. The double bar notation used to denote vector norms is also used for matrix norms. The properties of a matrix norm are similar to those of a vector norm.\n",
    "\n",
    "- $\\Vert \\vec{A} \\Vert \\geq 0$ for any matrix $\\vec{A} \\in \\mathbb{R}^{m \\times n}$\n",
    "  * $ \\Vert \\vec{A} \\Vert = 0$ if the matrix $\\vec{A} = 0$\n",
    "- $ \\Vert \\alpha \\vec{A} \\Vert = \\vert \\alpha \\vert \\Vert \\vec{A} \\Vert$ for a $m \\times n$ matrix and scalar $\\alpha$\n",
    "- $\\Vert \\vec{A} + \\vec{B} \\Vert \\leq \\Vert \\vec{A} \\Vert + \\Vert \\vec{B} \\Vert$ for $m \\times n$ matrices $\\vec{A}$ and $\\vec{B}$\n",
    "\n",
    "The most commonly occurring matrix norms in matrix analysis are the Frobenius, $L_1$, $L_2$ and $L_\\infty$ norms. The following will investigate these norms, along with some Python implementations of the calculation of the matrix norm. Before getting started, we create a $3 \\times 2$ matrix with random elements between $-10$ and $10$ that will be used for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8, -9],\n",
       "       [-1, -1],\n",
       "       [ 7,  4]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randint(-10, 10, size=(3, 2))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of matrix rows $n$ and columns $m$ will be required throughout to calculate the matrix norms. To get these values, we take the [`shape`](https://numpy.org/devdocs/reference/generated/numpy.shape.html) of the created matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n"
     ]
    }
   ],
   "source": [
    "n, m = a.shape\n",
    "print(n, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frobenius Norm\n",
    "\n",
    "The Frobenius norm, also known as the Hilbert-Schmidt norm or the Schur norm, is one of the most commonly employed matrix norms in linear algebra. The Frobenius norm is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n \\vert a_{ij} \\vert^2} $$\n",
    "\n",
    "A demonstrative implementation of the Frobenius norm in Python is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.560219778561036"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 0\n",
    "\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(m):\n",
    "        f = f + np.sum(np.power(np.abs(a[i, j]), 2))\n",
    "\n",
    "np.sqrt(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with vector norms, we can take advantage of `numpy`'s vectorization support to calculate the Frobenius norm with a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.560219778561036"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.abs(a) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our result by comparing it to the output of `numpy`'s [`norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) function. The `ord` parameter is specified as `'fro'` to output the Frobenius norm, but this is the default behavior when a matrix is passed to the `norm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.560219778561036"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, 'fro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $1$-Norm\n",
    "\n",
    "The matrix 1-norm is defined as the maximum absolute column sum of a matrix.\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_1 = \\underset{\\Vert \\vec{x} \\Vert_1 = 1}{\\max} \\Vert \\vec{Ax} \\Vert_1 = \\underset{1 \\leq j \\leq n}{\\max}\\left( \\sum^n_{i=1} \\vert a_{ij} \\vert \\right) $$\n",
    "\n",
    "Therefore, the $1$-Norm of a matrix is the maximum of the sum of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colsums = []\n",
    "for i in np.arange(m):\n",
    "    v = np.sum(np.abs(a[:, i]))\n",
    "    colsums.append(v)\n",
    "\n",
    "np.max(colsums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the `axis` parameter to `0`, `numpy`'s `sum` function will sum column-wise. This gives us a faster, one-line implementation of the matrix $1$-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.sum(np.abs(a), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming our results with the `norm` function in `numpy`'s `linalg` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\infty$-Norm\n",
    "\n",
    "The $\\infty$-norm of a matrix is defined as the maximum absolute sum of the matrix rows.\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_\\infty = \\underset{\\Vert \\vec{x} \\Vert_{\\infty} = 1}{\\max} \\Vert \\vec{Ax} \\Vert_{\\infty} = \\underset{1 \\leq i \\leq n}{\\max} \\left(\\sum^n_{j=1} \\vert a_{ij} \\vert \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsums = []\n",
    "for i in np.arange(n):\n",
    "    v = np.sum(np.absolute(a[i, :]))\n",
    "    rowsums.append(v)\n",
    "\n",
    "np.max(rowsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.sum(np.abs(a), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $2$-Norm\n",
    "\n",
    "Unlike the other norms shown above, the matrix $2$-norm is more difficult to characterize.\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_2 = \\underset{\\Vert \\vec{x} \\Vert_2}{\\max} \\Vert \\vec{Ax} \\Vert_2 $$\n",
    "\n",
    "After some tedious differentiation of a maximization function, it can be shown the matrix $2$-norm is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_2 = \\underset{1 \\leq i \\leq n}{\\max} \\sqrt{\\lambda_i (\\vec{A}^T \\vec{A})} $$\n",
    "\n",
    "Thus, the $2$-norm of a matrix is the square root of the maximum eigenvalue of the inner product of $\\vec{A}^T \\vec{A}$. Fortunately, `numpy`'s [`eigvals`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eigvals.html#numpy.linalg.eigvals) function allows us to easily calculate the eigenvalues and find the $2$-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.398483819270972"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our result by comparing it to the output of `numpy`'s [`norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.398483819270972"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequalities and Some Matrix Properties\n",
    "\n",
    "Now that the most commonly occurring matrix norms have been introduced, we turn to some interesting inequalities that arise in the analysis of matrix norms. The first inequality is a special case of Hölder's inequality and is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_2 \\leq \\sqrt{\\Vert \\vec{A} \\Vert_1 \\Vert \\vec{A} \\Vert_{\\infty}} $$\n",
    "\n",
    "We can demonstrate this inequality with a straightforward Python function. The following function creates a randomly sized matrix no bigger than $6 \\times 6$ and no smaller than $3 \\times 3$ with random elements between $-10$ and $10$. The $2$-norm, $1$-norm, and $\\infty$-norm are then computed and compared. The function is then run $100,000$ times with the results appended to a list. Using Python's [`any`](https://docs.python.org/3/library/functions.html#any) function, we can then verify that none of the appended results are `False`, which is the expectation of the inequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def holder_inequality():\n",
    "    mat_size = np.random.randint(3, 6, 2)\n",
    "    a = np.random.randint(-10, 10, size=mat_size)\n",
    "    \n",
    "    norm2 = np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))\n",
    "    norm1 = np.max(np.sum(np.abs(a), axis=0))\n",
    "    inf_norm = np.max(np.sum(np.abs(a), axis=1))\n",
    "    \n",
    "    return norm2 <= np.sqrt(norm1 * inf_norm)\n",
    "\n",
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(holder_inequality())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another inequality between the Frobenius and $2$-norm is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{A} \\Vert_2 \\leq \\Vert \\vec{A} \\Vert_F \\leq \\sqrt{n} \\Vert \\vec{A} \\Vert_2 $$\n",
    "\n",
    "The following function demonstrates the inequality by creating a random matrix similar to before and then computing the inequality. The function is then run $100,000$ times with the results appended to a list. All of the appended results should be `True`, which we verify with the `any` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def frobenius_2_norm_inequality():\n",
    "    mat_size = np.random.randint(3, 6, 2)\n",
    "    a = np.random.randint(-10, 10, size=mat_size)\n",
    "    \n",
    "    n = a.shape[1]\n",
    "    norm2 = np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))\n",
    "    frob = np.sqrt(np.sum(np.abs(a) ** 2))\n",
    "    \n",
    "    return norm2 <= frob <= np.sqrt(n) * norm2\n",
    "\n",
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(frobenius_2_norm_inequality())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some more inequalities that arise in the study of matrix norms. Each inequality is demonstrated similarly to the above.\n",
    "\n",
    "$$ \\large \\underset{i,j}{\\max} \\vert a_{ij} \\vert \\leq \\Vert \\vec{A} \\Vert_2 \\leq \\sqrt{mn} \\space \\underset{i,j}{\\max} \\vert a_{ij} \\vert $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inequality2():\n",
    "    mat_size = np.random.randint(3, 6, 2)\n",
    "    a = np.random.randint(-10, 10, size=mat_size)\n",
    "    maximum = np.max(np.abs(a))\n",
    "    norm2 = np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))\n",
    "    right = np.sqrt(a.shape[0] * a.shape[1]) * maximum\n",
    "    \n",
    "    return maximum <= norm2 <= right\n",
    "\n",
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(inequality2())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\frac{1}{\\sqrt{n}} \\Vert \\vec{A} \\Vert_\\infty \\leq \\Vert \\vec{A} \\Vert_2 \\leq \\sqrt{m} \\space \\Vert \\vec{A} \\Vert_\\infty $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inequality3():\n",
    "    mat_size = np.random.randint(3, 6, 2)\n",
    "    a = np.random.randint(0, 10, size=mat_size)\n",
    "    \n",
    "    inf_norm = np.max(np.sum(a, axis=1))\n",
    "    \n",
    "    left = 1 / np.sqrt(a.shape[1]) * inf_norm\n",
    "    norm2 = np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))\n",
    "    right = np.sqrt(a.shape[0]) * inf_norm\n",
    "\n",
    "    return left <= norm2 <= right\n",
    "\n",
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(inequality3())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\large \\frac{1}{\\sqrt{m}} \\Vert \\vec{A} \\Vert_1 \\leq \\Vert \\vec{A} \\Vert_2 \\leq \\sqrt{n} \\space \\Vert \\vec{A} \\Vert_1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inequality4():\n",
    "    mat_size = np.random.randint(3, 4, 2)\n",
    "    a = np.random.randint(0, 10, size=mat_size)\n",
    "    \n",
    "    norm1 = np.max(np.sum(a, axis=1))\n",
    "    norm2 = np.sqrt(np.max(np.linalg.eigvals(np.inner(a, a))))\n",
    "    right = np.sqrt(a.shape[1]) * norm1\n",
    "    \n",
    "    return 1 / np.sqrt(a.shape[0]) * norm1 <= norm2 <= right\n",
    "\n",
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(inequality4())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Golub, Gene; Van Loan, Charles F. (1996). Matrix Computations (Third ed.). Baltimore: The Johns Hopkins University Press.](https://amzn.to/34t0w09)\n",
    "\n",
    "[Wikipedia contributors. \"Matrix norm.\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 17 Apr. 2020. Web.\n",
    "18 Apr. 2020](https://en.wikipedia.org/wiki/Matrix_norm)\n",
    "\n",
    "[Wikipedia contributors. \"Norm (mathematics).\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 2 Mar. 2020. Web. 5 Apr. 2020.](https://en.wikipedia.org/wiki/Norm_(mathematics))\n",
    "\n",
    "Weisstein, Eric W. \"Matrix Norm.\" From MathWorld--A Wolfram Web Resource. https://mathworld.wolfram.com/MatrixNorm.html\n",
    "\n",
    "https://www.math.usm.edu/lambers/mat610/sum10/lecture2.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
