{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\renewcommand{\\vec}[1]{\\mathbf{#1}}$$\n",
    "Similar to the real line concerning two real scalars and the distance between them, $|a - b|$, vector norms allow us to get a sense of the distance or magnitude of a vector. In fact, a vector of length one is simply a scalar. Norms are often used in regularization methods and other machine learning procedures, as well as many different matrix and vector operations in linear algebra.   \n",
    "\n",
    "Formally, given a vector space $\\mathbb{R}^n$, a vector norm is defined as a function $f: \\mathbb{R}^n\n",
    "\\rightarrow \\mathbb{R}$. Norms are represented by double-bar notation, for example, a norm $x$ would be\n",
    "denoted $||x||$. Vector norms have the following properties:\n",
    "\n",
    "- $\\Vert \\vec{x} \\Vert > 0$ for a vector $x \\in \\mathbb{R}^n$\n",
    "  * $\\Vert \\vec{x} \\Vert = 0$ if the vector $\\vec{x} = 0$\n",
    "- $\\Vert \\alpha \\vec{x} \\vert = \\vert \\alpha \\vert \\Vert \\vec{x} \\Vert $ for a vector $\\vec{x} \\in \\mathbb{R}^n$ and a scalar\n",
    "    $\\alpha \\in \\mathbb{R}$\n",
    "- $\\Vert \\vec{x} + \\vec{y} \\Vert \\leq \\Vert \\vec{x} \\Vert + \\Vert \\vec{y} \\Vert$ for vectors $\\vec{x},\\vec{y} \\in \\mathbb{R}^n$\n",
    "\n",
    "The most commonly occurring vector norms are the $1$, $2$, and $\\infty$ norms, which are a part of the $p$-norm class of vector norms.\n",
    "\n",
    "## Vector Norms\n",
    "\n",
    "The following will explore the most frequently occurring vector norms $1$, $2$, and $\\infty$ and some Python implementations of the norms. We first create an array using `numpy`'s [`randint`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randint.html) function that will be used as our example vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, -3,  6, -3,  5, -9, -9,  8, -8,  2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randint(-10, 10, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Norm\n",
    "\n",
    "The 1-norm of a vector $x$ is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} \\Vert_1 = \\vert x_1 \\vert + \\vert x_2 \\vert + \\cdots + \\vert x_n \\vert $$\n",
    "\n",
    "The $1$-norm is often denoted $\\textit{l}_1$ or $L^1$ and is also referred to as the Taxicab norm. The following is an implementation of the calculation of the $1$-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "norm1 = 0\n",
    "\n",
    "for i in x:\n",
    "    norm1 += np.abs(i)\n",
    "    \n",
    "print(norm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than writing a (comparatively slow) loop, we can take advantage of `numpy`'s vectorization to calculate the $1$-norm as a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm our results with `Numpy`'s [`norm` function](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Norm\n",
    "\n",
    "The $2$-norm of a vector $x$ is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} \\Vert _2 = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2} = \\sqrt{\\vec{x}^T \\vec{x}} $$\n",
    "\n",
    "The $2$-norm is often denoted as $\\textit{l}_2$ or $L^2$ and is also referred to as the Euclidean length or distance. An example implementation of the $2$-norm calculation is somewhat similar to the $1$-norm computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.4164878389476\n"
     ]
    }
   ],
   "source": [
    "norm2 = 0\n",
    "\n",
    "for i in x:\n",
    "    norm2 += i ** 2\n",
    "\n",
    "print(np.sqrt(norm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of computing the $2$-norm of a vector as a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4164878389476"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.power(x, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definition of the $2$-norm above, we know the above computations is also equal to the square root of the [inner product](https://en.wikipedia.org/wiki/Dot_product#Inner_product) of the vector and the [conjugate transpose](https://en.wikipedia.org/wiki/Conjugate_transpose). `Numpy` provides an [`inner`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.inner.html) function for computing the inner product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4164878389476"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.inner(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can verify our calculations of the $2$-norm by using `numpy`'s `norm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4164878389476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Norm\n",
    "\n",
    "The p-norm, which is considered a class of vector norms is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} \\Vert_p = \\sqrt[p]{\\vert x_1 \\vert^p + \\vert x_2 \\vert^p + \\cdots + \\vert x_n \\vert^p} \\qquad p \\geq 1 $$\n",
    "\n",
    "By setting $p$ equal to $1$ or $2$, we can find the $1$ and $2$-norm of a vector without the need for separate equations and functions. Below we calculate the $2$-norm of a vector using the $p$-norm equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4164878389476"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnorm = 0\n",
    "p = 2\n",
    "\n",
    "for i in x:\n",
    "    pnorm += np.abs(i) ** p\n",
    "pnorm ** (1. / p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more simple and one-liner implementation of the $p$-norm class of vector norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.4164878389476"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(x) ** p) ** (1. / p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-norm is not limited to $p = 1$ or $p = 2$, but $p$ cannot be less than $1$ or complex. Here, we compute the vector $3$-norm and compare the results with `numpy`'s `norm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.24894831676299\n",
      "14.24894831676299\n"
     ]
    }
   ],
   "source": [
    "p = 3\n",
    "print(np.sum(np.abs(x) ** p) ** (1. / p))\n",
    "print(np.linalg.norm(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf-Norm\n",
    "\n",
    "The $\\infty$ norm of a vector $\\vec{x}$ is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} \\Vert_{\\infty} = \\underset{1 \\leq i \\leq n}{\\max} \\vert x_i \\vert $$\n",
    "\n",
    "The $\\infty$-norm of a vector is the maximum absolute value of the elements in the vector. Below is one possible example implementation of finding the $\\infty$-norm of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_abs = np.abs(x)\n",
    "infnorm = x_abs[0]\n",
    "\n",
    "for i in x_abs[1:]:\n",
    "    if infnorm < i:\n",
    "        infnorm = i\n",
    "        \n",
    "infnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more easy and straightforward approach to finding the $\\infty$-norm using `numpy`'s [`max`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.max.html) and `absolute` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can compare our results with `numpy`'s `norm` function by setting the function's `ord` parameter ($p$) to `numpy`'s [`inf`](https://numpy.org/devdocs/reference/constants.html#numpy.inf) constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we take a look at the $-\\infty$-norm, which can be thought of as the opposite of the $\\infty$-norm.\n",
    "\n",
    "### -Inf-Norm\n",
    "\n",
    "The $-\\infty$ norm of a vector $\\vec{x}$ is defined as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} \\Vert_{\\infty} = \\underset{1 \\leq i \\leq n}{\\min} \\vert x_i \\vert $$\n",
    "\n",
    "The $-\\infty$-norm of a vector is the minimum absolute value of the elements in the vector. The following example implementation of finding the $-\\infty$-norm is quite similar to the $\\infty$-norm implementation example, except here we are looking for the smallest value rather than the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_infnorm = x_abs[0]\n",
    "\n",
    "for i in x_abs[1:]:\n",
    "    if neg_infnorm > i:\n",
    "        neg_infnorm = i\n",
    "        \n",
    "neg_infnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much more easy and simple implementation of finding the $-\\infty$-norm of a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.abs(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, setting the `ord` parameter to `numpy`'s negative `inf` constant, we can confirm our calculations of the $-\\infty$-norm above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x, -np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inequalities\n",
    "\n",
    "Now that the most common and important vector norms have been introduced, we turn our attention towards some \n",
    "interesting inequalities that arise from the study of vector norms.\n",
    "\n",
    "### Cauchy-Schwartz Inequality\n",
    "\n",
    "In the linear and vector algebra, The Cauchy-Schwartz inequality, sometimes referred to as the Cauchy–Bunyakovsky–Schwarz inequality states that for any two vectors, denoted $\\vec{x}$ and $\\vec{y}$, the following is true:\n",
    "\n",
    "$$ \\large \\vert \\langle \\vec{x}, \\vec{y} \\rangle \\vert^2 \\geq \\langle \\vec{x}, \\vec{x} \\rangle \\cdot \\langle \\vec{y}, \\vec{y} \\rangle $$\n",
    "\n",
    "The inequality can be rewritten for vector norms as the following:\n",
    "\n",
    "$$ \\large |\\vec{x}^T \\vec{y}| \\leq  \\Vert \\vec{x} \\Vert_2\\Vert \\vec{y} \\Vert_2 $$\n",
    "\n",
    "Which states that for any two vectors $\\vec{x}$ and $\\vec{y}$, the inner product of $\\vec{x}$ and $\\vec{y}$ will always be less than or equal to the product of the $2$-norms of the vectors.\n",
    "\n",
    "The proof of the Cauchy-Schwartz inequality is beyond the scope of this post; however, we can write a simple function to demonstrate the inequality. The following function creates two vectors of length $10$ with elements between $1$ and $100$ using `numpy`'s [`randint`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.randint.html) function. The inner product is computed with `numpy`'s [`inner`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.inner.html) function and is then compared with the right side of the inequality. The function will return `True` if the inequality holds and `False` otherwise. Thus, the function should always return `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy_schwartz_inequality():\n",
    "    x = np.random.randint(1, 100, 10)\n",
    "    y = np.random.randint(1, 100, 10)\n",
    "    \n",
    "    inner_prod = np.inner(x, y)\n",
    "    right = np.sqrt(np.sum(np.power(x, 2))) * np.sqrt(np.sum(np.power(y, 2)))\n",
    "    \n",
    "    return inner_prod <= right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tests the inequality by running the `cauchy_schwartz_inequality()` function created above $100,000$ times and appends the results to a list. Using Python's [`any`](https://docs.python.org/3/library/functions.html#any) method, we can then see if any of the appended results in the list is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(cauchy_schwartz_inequality())\n",
    "    \n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hölder's Inequality\n",
    "\n",
    "It can be shown the Cauchy-Schwartz inequality is a special case of Hölder's Inequality, which in the linear algebra setting can be defined as: \n",
    "\n",
    "$$ \\large \\vert \\vec{x}^T \\vec{y} \\vert \\leq \\Vert \\vec{x} \\Vert_p \\Vert \\vec{y} \\Vert_q, \\qquad \\frac{1}{p} + \\frac{1}{q} = 1 $$\n",
    "\n",
    "The variables $p$ and $q$ are known as Hölder conjugates. The inequality thus states that the inner product of two vectors $\\vec{x}$ and $\\vec{y}$ will always be less than equal to the product of $p$-norms of the vectors where $\\frac{1}{p} + \\frac{1}{q} = 1$. As before, the proof of Hölder's inequality is beyond the scope of this post, but we can write a function to demonstrate the inequality. The following function creates two vectors of length ten with random elements between $1$ and $100$ and a number $p$ between $2$ and $10$. The conjugate number $q$ is then found, and the inner product and right side of the inequality are computed. The function then returns `True` if the inner product is less than or greater to the right side of the inequality and `False` otherwise. We also return the calculation $1 / p + 1 / q$ to ensure it is always equal to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holder_inequality():\n",
    "    x = np.random.randint(1, 100, 10)\n",
    "    y = np.random.randint(1, 100, 10)\n",
    "    \n",
    "    p = np.random.randint(2, 10)\n",
    "    q = p / (p - 1)\n",
    "    \n",
    "    inner_prod = np.inner(x, y)\n",
    "    right = np.sum(np.abs(x) ** p) ** (1. / p) * np.sum(np.abs(y) ** q) ** (1. / q)\n",
    "    \n",
    "    return inner_prod <= right, int(1 / p + 1 / q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then test the inequality by running the function $100,000$ times and append the results to a list. Given the inequality's definition, the result should always be `True` and $1$ for the $1/p + 1/q$ calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False values exist in result: False\n",
      "All conjugate calculations are equal to 1: True\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(holder_inequality())\n",
    "\n",
    "print('False values exist in result:', any(x[0] == False for x in res))\n",
    "print('All conjugate calculations are equal to 1:', all(x[1] == 1 for x in res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski's Inequality\n",
    "\n",
    "The final inequality we shall investigate is known as Minkowski's inequality for norms. Minkowski's inequality for norms is also known as the triangle inequality. For two vectors, $\\vec{x}$ and $\\vec{y}$ of length $n$, Minkowski's inequality can be written as:\n",
    "\n",
    "$$ \\large \\left( \\sum^n_{i=1} \\left(\\vert \\vec{x}_i + \\vec{y}_i \\vert \\right)^p \\right)^{\\frac{1}{p}} \\leq \\left(\\sum^n_{i=1} \\vert \\vec{x}_i \\vert^p \\right)^{\\frac{1}{p}} + \\left(\\sum^n_{i=1} \\vert \\vec{y}_i \\vert^p \\right)^{\\frac{1}{p}} $$\n",
    "\n",
    "Which can be more simply written using vector norms as:\n",
    "\n",
    "$$ \\large \\Vert \\vec{x} + \\vec{y} \\Vert_p \\leq \\Vert \\vec{x} \\Vert_p \\Vert \\vec{y} \\Vert_p $$\n",
    "\n",
    "Similar to the other inequalities we examined previously, we can demonstrate Minkowski's inequality for norms by writing a fairly straightforward function. The function `minkowski_inequality()` creates two vectors of length ten with random integer elements between $1$ and $100$ and a $p$ number between $1$ and $5$. The left and right sides of the inequality are then computed, and the function returns `True` if the left side is less than or equal to the right side and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_inequality():\n",
    "    x = np.random.randint(1, 100, 10)\n",
    "    y = np.random.randint(1, 100, 10)\n",
    "    \n",
    "    p = np.random.randint(1, 5)\n",
    "    \n",
    "    left = np.sum(np.abs(x + y) ** p) ** (1. / p)\n",
    "    right = np.sum(np.abs(x) ** p) ** (1. / p) + np.sum(np.abs(y) ** p) ** (1. / p)\n",
    "    \n",
    "    return left <= right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the definition of Minkowski's inequality, the function should always return `True`. We test this by running the function $100,000$ times and appending the results to a list. Then, with Python's [`any`](https://docs.python.org/3/library/functions.html#any) function, we check that the appended list of results does not contain a `False` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for i in range(0, 100000):\n",
    "    res.append(minkowski_inequality())\n",
    "\n",
    "any(x == False for x in res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Golub, Gene; Van Loan, Charles F. (1996). Matrix Computations (Third ed.). Baltimore: The Johns Hopkins University Press.](https://amzn.to/34t0w09)\n",
    "\n",
    "[Hardy, G. H.; Littlewood, J. E.; Pólya, G. (1952). Inequalities. Cambridge Mathematical Library (second ed.). Cambridge: Cambridge University Press.](https://amzn.to/2XtADfw)\n",
    "\n",
    "[Wikipedia contributors. \"Cauchy–Schwarz inequality.\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 12 Apr. 2020. Web. 16 Apr. 2020.](https://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality)\n",
    "\n",
    "[Wikipedia contributors. \"Minkowski inequality.\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 2 Apr. 2020. Web. 12 Apr. 2020.](https://en.wikipedia.org/wiki/Minkowski_inequality)\n",
    "\n",
    "[Wikipedia contributors. \"Norm (mathematics).\" Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 2 Mar. 2020. Web. 5 Apr. 2020.](https://en.wikipedia.org/wiki/Norm_(mathematics))\n",
    "\n",
    "Weisstein, Eric W. \"Vector Norm.\" From MathWorld--A Wolfram Web Resource. https://mathworld.wolfram.com/VectorNorm.\n",
    "\n",
    "https://www.cis.upenn.edu/~cis515/cis515-11-sl4.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
