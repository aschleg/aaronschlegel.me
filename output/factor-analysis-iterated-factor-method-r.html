<!DOCTYPE html>
<html lang="english">
<head>

        <title>Factor Analysis with the Iterated Factor Method and R</title>
        <meta charset="utf-8" />
        <link href="https://aaronschlegel.me/feed/all.xml" type="application/atom+xml" rel="alternate" title="Aaron Schlegel's Notebook of Interesting Things Full Atom Feed" />
        <link href="https://aaronschlegel.me/feed/statistics.xml" type="application/atom+xml" rel="alternate" title="Aaron Schlegel's Notebook of Interesting Things Categories Atom Feed" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">
        <meta name="description" content="The iterated principal factor method is an extension of the principal" />
        <meta property="og:site_name" content="Aaron Schlegel's Notebook of Interesting Things" />
        <meta property="og:type" content="article" />
        <meta property="og:title" content="Factor Analysis with the Iterated Factor Method and R" />
        <meta property="og:url" content="https://aaronschlegel.me" />
        <meta property="og:description" content="" />
        <meta property="article:published_time" content="2017-03-03 00:00:00-08:00" />
        <meta property="article:modified_time" content="" />
        <meta name="twitter:site" content="@Aaron_Schlegel" />
        <meta name="twitter:creator" content="@Aaron_Schlegel" />
        <meta name="twitter:card" content="The iterated principal factor method is an extension of the principal" />
        <meta name="twitter:card" content="The Blog and Notebooks of Aaron Schlegel" />

        <link rel="stylesheet" type="text/css" href="https://aaronschlegel.me/theme/css/styles.min.css" />
        <link rel="canonical" href="https://aaronschlegel.me/factor-analysis-iterated-factor-method-r.html" />

        <script src="https://aaronschlegel.me/theme/js/libs/modernizr-2.6.2.min.js"></script>

              <script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-48350829-2', 'aaronschlegel.me');
                ga('send', 'pageview');

              </script>


</head>

<body id="index" class="home">
    <div class="container">
        <div class="row">

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>

              <ul class="columns-right">
                <li><a href="https://aaronschlegel.me/">Home</a></li>

                <li><a href="https://aaronschlegel.me/pages/projects.html">Projects</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">
            <header>
              <h2 class="entry-title">
                <a href="https://aaronschlegel.me/factor-analysis-iterated-factor-method-r.html" rel="bookmark"
                   title="Permalink to Factor Analysis with the Iterated Factor Method and R">Factor Analysis with the Iterated Factor Method and R</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2017-03-03T00:00:00-08:00">
                Fri 03 March 2017
              </abbr>
              <address class="vcard author">By 
                <a class="url fn" href="https://aaronschlegel.me/author/aaron-schlegel.html"> Aaron Schlegel</a>
              </address>
            </footer><!-- /.post-info -->
            <div class="entry-content">
                <p>factor method that seeks improved estimates of the communality. In the iterated 
principal factor method, the initial estimates of the communality are used to 
find new communality estimates from the loadings. The iterated principal factor method is demonstrated on the rootstock
data as in the previous posts on factor analysis for consistency and
comparison of the various approaches.</p>
<p>The iterated principal factor method is an extension of the <a href="https://aaronschlegel.me/factor-analysis-principal-factor-r.html">principal
factor method</a> 
that seeks improved estimates of the communality. As seen in the previous post on the principal factor
method, initial estimates of <span class="math">\(R - \hat{\Psi}\)</span> or <span class="math">\(S - \hat{\Psi}\)</span> are
found to obtain <span class="math">\(\hat{\Lambda}\)</span> from which the factors are computed. In
the iterated principal factor method, the initial estimates of the
communality are used to find new communality estimates from the loadings
in <span class="math">\(\hat{\Lambda}\)</span> with the following:</p>
<div class="math">$$ \hat{h}^2_i = \sum^m_{j=1} \hat{\lambda}^2_{ij} $$</div>
<p>The values of <span class="math">\(\hat{h}^2_i\)</span> are then substituted into the diagonal of
<span class="math">\(R - \hat{\Psi}\)</span> or <span class="math">\(S - \hat{\Psi}\)</span> and a new value of <span class="math">\(\hat{\Lambda}\)</span>
is found. This iteration continues until the communality estimates
converge, though sometimes convergence does not occur. Once the
estimates converge, the eigenvalues and eigenvectors are calculated from
the iterated <span class="math">\(R - \hat{\Psi}\)</span> or <span class="math">\(S - \hat{\Psi}\)</span> matrix to arrive at
the factor loadings.</p>
<h2>The Iterated Principal Factor Method in R</h2>
<p>The iterated principal factor method is demonstrated on the rootstock
data as in the previous posts on factor analysis for consistency and
comparison of the various approaches. The rootstock data contain four
variables representing measurements in different units taken at four and
fifteen years growth of six different rootstocks. The data were obtained
from the <a href="ftp://ftp.wiley.com">companion FTP site</a> of the book Methods
of Multivariate Analysis by Alvin Rencher. The data contains four
dependent variables as follows:</p>
<ul>
<li>trunk girth at four years (mm <span class="math">\(\times\)</span> 100)</li>
<li>extension growth at four years (m)</li>
<li>trunk girth at 15 years (mm <span class="math">\(\times\)</span> 100)</li>
<li>weight of tree above ground at 15 years (lb <span class="math">\(\times\)</span> 1000)</li>
</ul>
<p>Load the data and name the columns.</p>
<div class="highlight"><pre><span></span><span class="n">root</span> <span class="o">&lt;-</span> <span class="nf">read.table</span><span class="p">(</span><span class="s">&#39;ROOT.DAT&#39;</span><span class="p">,</span> <span class="n">col.names</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Tree.Number&#39;</span><span class="p">,</span> <span class="s">&#39;Trunk.Girth.4.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Ext.Growth.4.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Trunk.Girth.15.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Weight.Above.Ground.15.Years&#39;</span><span class="p">))</span>
</pre></div>


<p>We proceed with the correlation matrix <span class="math">\(R\)</span> as the variables in the data
are not measured commensurately. Using <span class="math">\(R\)</span> over <span class="math">\(S\)</span> is generally the
preferred approach and is usually the default in most implementations
(such as the <code>psych</code> package).</p>
<p>Calculate the correlation matrix.</p>
<div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">&lt;-</span> <span class="nf">cor</span><span class="p">(</span><span class="n">root</span><span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="p">])</span>
</pre></div>


<p>The initial estimates of the communality are found by computing the
squared multiple correlation, which in the case of <span class="math">\(R - \hat{\Psi}\)</span> is
equal to the following:</p>
<div class="math">$$ \hat{h}^2_i = 1 - \frac{1}{r^{ii}} $$</div>
<p>Where <span class="math">\(r^{ii}\)</span> is the <span class="math">\(i\)</span>th diagonal element of <span class="math">\(R^{-1}\)</span>.</p>
<div class="highlight"><pre><span></span><span class="n">R.smc</span> <span class="o">&lt;-</span> <span class="p">(</span><span class="m">1</span> <span class="o">-</span> <span class="m">1</span> <span class="o">/</span> <span class="nf">diag</span><span class="p">(</span><span class="nf">solve</span><span class="p">(</span><span class="n">R</span><span class="p">)))</span>
</pre></div>


<p>The estimates then replace the diagonal of <span class="math">\(R\)</span>.</p>
<div class="highlight"><pre><span></span><span class="nf">diag</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">R.smc</span>
</pre></div>


<p>The threshold for convergence of the communality is set to <span class="math">\(0.001\)</span>. This
error threshold is also the default in the <code>psych</code> package
implementation of the iterated principal factor method. The <code>com.iter</code>
object will be used to store the communality iterations.</p>
<div class="highlight"><pre><span></span><span class="n">min.error</span> <span class="o">&lt;-</span> <span class="n">.</span><span class="m">001</span>
<span class="n">com.iter</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">()</span>
</pre></div>


<p><span class="math">\(\hat{h}^2_i\)</span> is then found from
<span class="math">\(\hat{h}^2_i = \sum^m_{j=1} \hat{\lambda}^2_{ij}\)</span>, which is simply the
sum of the diagonal of <span class="math">\(R\)</span> (<span class="math">\(R\)</span> will be replaced with <span class="math">\(\hat{\Lambda}\)</span> in
the iteration).</p>
<div class="highlight"><pre><span></span><span class="n">h2</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">diag</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
<span class="n">error</span> <span class="o">&lt;-</span> <span class="n">h2</span>
</pre></div>


<p>The following loop implements the iterated principal factor method using
<span class="math">\(R\)</span> with the estimated communalities found earlier. While our
communality estimate remains above the error threshold of <span class="math">\(0.001\)</span>, the
loop will continue to calculate new values of <span class="math">\(\hat{\Lambda}\)</span> by
replacing the previous estimates of communality with new ones.</p>
<div class="highlight"><pre><span></span><span class="nf">while </span><span class="p">(</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">min.error</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">r.eigen</span> <span class="o">&lt;-</span> <span class="nf">eigen</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="c1"># Get the eigenvalues and eigenvectors of R</span>

  <span class="c1"># The lambda object is updated upon each iteration using new estimates of the communality</span>
  <span class="n">lambda</span> <span class="o">&lt;-</span> <span class="nf">as.matrix</span><span class="p">(</span><span class="n">r.eigen</span><span class="o">$</span><span class="n">vectors</span><span class="p">[,</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">])</span> <span class="o">%*%</span> <span class="nf">diag</span><span class="p">(</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">r.eigen</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">]))</span>

  <span class="c1"># R - Psi is then found by multiplying the lambda matrix by its transpose</span>
  <span class="n">r.mod</span> <span class="o">&lt;-</span> <span class="n">lambda</span> <span class="o">%*%</span> <span class="nf">t</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span>
  <span class="n">r.mod.diag</span> <span class="o">&lt;-</span> <span class="nf">diag</span><span class="p">(</span><span class="n">r.mod</span><span class="p">)</span> <span class="c1"># The diagonal of R - Psi is the new communality estimate</span>

  <span class="c1"># The sum of the new estimate is taken and compared with the previous estimate. If the</span>
  <span class="c1"># difference is less than the error threshold the loop stops</span>
  <span class="n">h2.new</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="n">r.mod.diag</span><span class="p">)</span> 
  <span class="n">error</span> <span class="o">&lt;-</span> <span class="nf">abs</span><span class="p">(</span><span class="n">h2</span> <span class="o">-</span> <span class="n">h2.new</span><span class="p">)</span>

  <span class="c1"># If the difference between the previous and new estimate is not below the threshold, replace</span>
  <span class="c1"># the new estimate with the previous</span>
  <span class="n">h2</span> <span class="o">&lt;-</span> <span class="n">h2.new</span>

  <span class="c1"># Store the iteration value (the sum of the estimate) and replace the diagonal of R with the</span>
  <span class="c1"># diagonal of R - Psi found previously</span>
  <span class="n">com.iter</span> <span class="o">&lt;-</span> <span class="nf">append</span><span class="p">(</span><span class="n">com.iter</span><span class="p">,</span> <span class="n">h2.new</span><span class="p">)</span>
  <span class="nf">diag</span><span class="p">(</span><span class="n">R</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="n">r.mod.diag</span>
<span class="p">}</span>
</pre></div>


<p>We now have the final <span class="math">\(\hat{\Lambda}\)</span>. Find the communality, specific
variances and complexity and collect them into a <code>data.frame</code></p>
<div class="highlight"><pre><span></span><span class="n">h2</span> <span class="o">&lt;-</span> <span class="nf">rowSums</span><span class="p">(</span><span class="n">lambda</span><span class="o">^</span><span class="m">2</span><span class="p">)</span>
<span class="n">u2</span> <span class="o">&lt;-</span> <span class="m">1</span> <span class="o">-</span> <span class="n">h2</span>
<span class="n">com</span> <span class="o">&lt;-</span> <span class="nf">rowSums</span><span class="p">(</span><span class="n">lambda</span><span class="o">^</span><span class="m">2</span><span class="p">)</span><span class="o">^</span><span class="m">2</span> <span class="o">/</span> <span class="nf">rowSums</span><span class="p">(</span><span class="n">lambda</span><span class="o">^</span><span class="m">4</span><span class="p">)</span>

<span class="n">iter.fa.loadings</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="nf">cbind</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">lambda</span><span class="p">,</span><span class="m">2</span><span class="p">),</span> <span class="nf">round</span><span class="p">(</span><span class="n">h2</span><span class="p">,</span> <span class="m">2</span><span class="p">),</span> <span class="nf">round</span><span class="p">(</span><span class="n">u2</span><span class="p">,</span> <span class="m">3</span><span class="p">),</span> <span class="nf">round</span><span class="p">(</span><span class="n">com</span><span class="p">,</span> <span class="m">2</span><span class="p">)))</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">iter.fa.loadings</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Factor 1&#39;</span><span class="p">,</span> <span class="s">&#39;Factor 2&#39;</span><span class="p">,</span> <span class="s">&#39;h2&#39;</span><span class="p">,</span> <span class="s">&#39;u2&#39;</span><span class="p">,</span> <span class="s">&#39;com&#39;</span><span class="p">)</span>
</pre></div>


<p>The proportion of variance explained by the factors is found by:</p>
<div class="math">$$ \frac{\theta_j}{tr(R - \hat{\Psi})} = \frac{\theta_j}{\sum^p_{i=1} \theta_i} $$</div>
<p>Where <span class="math">\(\theta_j\)</span> is the <span class="math">\(j\)</span>th eigenvalue of <span class="math">\(R - \hat{\Psi}\)</span>. The
cumulative variance of the factors when factoring <span class="math">\(R\)</span> is found by:</p>
<div class="math">$$ \frac{\sum^p_{i=1} \hat{\lambda}^2_{ij}}{tr(R)} = \frac{\theta_j}{p} $$</div>
<p>Where <span class="math">\(p\)</span> is the number of variables. Calculate these values and store
in a <code>data.frame</code>.</p>
<div class="highlight"><pre><span></span><span class="n">prop.var</span> <span class="o">&lt;-</span> <span class="n">r.eigen</span><span class="o">$</span><span class="n">values</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">]</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="nf">diag</span><span class="p">(</span><span class="n">R</span><span class="p">))</span>
<span class="n">var.cumulative</span> <span class="o">&lt;-</span> <span class="n">r.eigen</span><span class="o">$</span><span class="n">values</span> <span class="o">/</span> <span class="m">4</span>

<span class="n">factor.var</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="nf">rbind</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">prop.var</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">],</span> <span class="m">2</span><span class="p">),</span> <span class="nf">round</span><span class="p">(</span><span class="n">var.cumulative</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="m">2</span><span class="p">],</span> <span class="m">2</span><span class="p">)))</span>
<span class="nf">rownames</span><span class="p">(</span><span class="n">factor.var</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Proportion Explained&#39;</span><span class="p">,</span> <span class="s">&#39;Cumulative Variance&#39;</span><span class="p">)</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">factor.var</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Factor 1&#39;</span><span class="p">,</span> <span class="s">&#39;Factor 2&#39;</span><span class="p">)</span>
<span class="n">factor.var</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##                      Factor 1 Factor 2</span>
<span class="err">## Proportion Explained     0.74     0.26</span>
<span class="err">## Cumulative Variance      0.68     0.24</span>
</pre></div>


<p>The iterated principal factor method of factor analysis is complete, and
we can now print the results!</p>
<div class="highlight"><pre><span></span><span class="n">iter.fa.res</span> <span class="o">&lt;-</span> <span class="nf">list</span><span class="p">(</span><span class="n">iter.fa.loadings</span><span class="p">,</span> <span class="n">factor.var</span><span class="p">)</span>
<span class="n">iter.fa.res</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## [[1]]</span>
<span class="err">##   Factor 1 Factor 2   h2    u2  com</span>
<span class="err">## 1    -0.76     0.56 0.89 0.109 1.84</span>
<span class="err">## 2    -0.82     0.46 0.88 0.116 1.57</span>
<span class="err">## 3    -0.88    -0.42 0.94 0.055 1.44</span>
<span class="err">## 4    -0.83    -0.52 0.96 0.042 1.68</span>
<span class="err">## </span>
<span class="err">## [[2]]</span>
<span class="err">##                      Factor 1 Factor 2</span>
<span class="err">## Proportion Explained     0.74     0.26</span>
<span class="err">## Cumulative Variance      0.68     0.24</span>
</pre></div>


<p>Interpretation of the factor loadings should be held until the factors
are rotated. We will also compare the results of the iterated approach
to the principal component method. Let's compare our results with the
output of the <code>psych</code> package to verify.</p>
<h2>Iterated Principal Factor Method with the <code>psych</code> Package</h2>
<p>The function <code>fa()</code> available in the <a href="https://cran.r-project.org/web/packages/psych/">psych
package</a> defaults to the
iterated approach. We keep the <code>rotate</code> argument set to <code>none</code> for now
and the <code>fm</code> argument to <code>pa</code> (principal axis, another term for
principal factors).</p>
<div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">psych</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">root.cor.fa</span> <span class="o">&lt;-</span> <span class="nf">fa</span><span class="p">(</span><span class="n">root</span><span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="p">],</span> <span class="n">nfactors</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="n">rotate</span> <span class="o">=</span> <span class="s">&#39;none&#39;</span><span class="p">,</span> <span class="n">fm</span> <span class="o">=</span> <span class="s">&#39;pa&#39;</span><span class="p">)</span>
<span class="n">root.cor.fa</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## Factor Analysis using method =  pa</span>
<span class="err">## Call: fa(r = root[, 2:5], nfactors = 2, rotate = &quot;none&quot;, fm = &quot;pa&quot;)</span>
<span class="err">## Standardized loadings (pattern matrix) based upon correlation matrix</span>
<span class="err">##                               PA1   PA2   h2    u2 com</span>
<span class="err">## Trunk.Girth.4.Years          0.76  0.56 0.89 0.109 1.8</span>
<span class="err">## Ext.Growth.4.Years           0.82  0.46 0.88 0.116 1.6</span>
<span class="err">## Trunk.Girth.15.Years         0.88 -0.42 0.94 0.055 1.4</span>
<span class="err">## Weight.Above.Ground.15.Years 0.83 -0.52 0.96 0.042 1.7</span>
<span class="err">## </span>
<span class="err">##                        PA1  PA2</span>
<span class="err">## SS loadings           2.71 0.97</span>
<span class="err">## Proportion Var        0.68 0.24</span>
<span class="err">## Cumulative Var        0.68 0.92</span>
<span class="err">## Proportion Explained  0.74 0.26</span>
<span class="err">## Cumulative Proportion 0.74 1.00</span>
<span class="err">## </span>
<span class="err">## Mean item complexity =  1.6</span>
<span class="err">## Test of the hypothesis that 2 factors are sufficient.</span>
<span class="err">## </span>
<span class="err">## The degrees of freedom for the null model are  6  and the objective function was  4.19 with Chi Square of  187.92</span>
<span class="err">## The degrees of freedom for the model are -1  and the objective function was  0.06 </span>
<span class="err">## </span>
<span class="err">## The root mean square of the residuals (RMSR) is  0.01 </span>
<span class="err">## The df corrected root mean square of the residuals is  NA </span>
<span class="err">## </span>
<span class="err">## The harmonic number of observations is  48 with the empirical chi square  0.03  with prob &lt;  NA </span>
<span class="err">## The total number of observations was  48  with Likelihood Chi Square =  2.75  with prob &lt;  NA </span>
<span class="err">## </span>
<span class="err">## Tucker Lewis Index of factoring reliability =  1.128</span>
<span class="err">## Fit based upon off diagonal values = 1</span>
<span class="err">## Measures of factor score adequacy             </span>
<span class="err">##                                                    PA1  PA2</span>
<span class="err">## Correlation of (regression) scores with factors   0.99 0.96</span>
<span class="err">## Multiple R square of scores with factors          0.97 0.92</span>
<span class="err">## Minimum correlation of possible factor scores     0.94 0.85</span>
</pre></div>


<p>The output matches our results other than an arbitrary scaling of <span class="math">\(-1\)</span>
on the first factor in our calculations (notice this does not affect the
communality or other computations as the loadings are squared). We can
also see the <code>fa()</code> function had the same iterations as our loop using
the <code>com.iter</code> object from earlier.</p>
<div class="highlight"><pre><span></span><span class="n">com.iter</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## [1] 3.553558 3.615064 3.645859 3.661351 3.669220 3.673293 3.675480 3.676730</span>
<span class="err">## [9] 3.677517</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">root.cor.fa</span><span class="o">$</span><span class="n">communality.iterations</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## [1] 3.553558 3.615064 3.645859 3.661351 3.669220 3.673293 3.675480 3.676730</span>
<span class="err">## [9] 3.677517</span>
</pre></div>


<h2>Rotation of Factors</h2>
<p>The factors should be rotated so the variables load highly on one factor
to better identify the groupings of the variables. Rotation also yields
a simple structure of the data which is denoted by the complexity value
calculated previously and improves interpretation of the factors.</p>
<p>The <code>varimax()</code> function can be used to rotate our computed factor
loadings. Varimax rotation is a type of orthogonal rotation, in which
the perpendicular axes remain perpendicular and the communality remains
the same after rotation. Orthogonal rotations also result in
uncorrelated factor loadings which can be useful for interpretation.</p>
<div class="highlight"><pre><span></span><span class="n">lambda.v</span> <span class="o">&lt;-</span> <span class="nf">varimax</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span><span class="o">$</span><span class="n">loadings</span>
<span class="n">lambda.v</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## </span>
<span class="err">## Loadings:</span>
<span class="err">##      [,1]   [,2]  </span>
<span class="err">## [1,] -0.182  0.926</span>
<span class="err">## [2,] -0.295  0.893</span>
<span class="err">## [3,] -0.931  0.281</span>
<span class="err">## [4,] -0.963  0.177</span>
<span class="err">## </span>
<span class="err">##                 [,1]  [,2]</span>
<span class="err">## SS loadings    1.912 1.765</span>
<span class="err">## Proportion Var 0.478 0.441</span>
<span class="err">## Cumulative Var 0.478 0.919</span>
</pre></div>


<p>Otherwise, setting the <code>rotate</code> argument to <code>varimax</code> in the <code>fa()</code>
function will perform varimax rotation.</p>
<h2>Comparison of Iterated Principal Factors and Principal Component Method</h2>
<p>We saw the non-iterated principal factor approach previously, and the
<a href="https://aaronschlegel.me/factor-analysis-principal-component-method-r.html">principal component method</a> reported similar
results; however, factor loadings from principal components loaded
slightly higher on their respective variables and represented the more
cumulative variance of the original data. Let's see if the iterated
method performs any better to the principal component method.</p>
<div class="highlight"><pre><span></span><span class="n">root.cor.fa</span> <span class="o">&lt;-</span> <span class="nf">fa</span><span class="p">(</span><span class="n">root</span><span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="p">],</span> <span class="n">nfactors</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="n">rotate</span> <span class="o">=</span> <span class="s">&#39;varimax&#39;</span><span class="p">,</span> <span class="n">fm</span> <span class="o">=</span> <span class="s">&#39;pa&#39;</span><span class="p">)</span>
<span class="n">root.cor.fa</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## Factor Analysis using method =  pa</span>
<span class="err">## Call: fa(r = root[, 2:5], nfactors = 2, rotate = &quot;varimax&quot;, fm = &quot;pa&quot;)</span>
<span class="err">## Standardized loadings (pattern matrix) based upon correlation matrix</span>
<span class="err">##                               PA1  PA2   h2    u2 com</span>
<span class="err">## Trunk.Girth.4.Years          0.18 0.93 0.89 0.109 1.1</span>
<span class="err">## Ext.Growth.4.Years           0.30 0.89 0.88 0.116 1.2</span>
<span class="err">## Trunk.Girth.15.Years         0.93 0.28 0.94 0.055 1.2</span>
<span class="err">## Weight.Above.Ground.15.Years 0.96 0.18 0.96 0.042 1.1</span>
<span class="err">## </span>
<span class="err">##                        PA1  PA2</span>
<span class="err">## SS loadings           1.91 1.77</span>
<span class="err">## Proportion Var        0.48 0.44</span>
<span class="err">## Cumulative Var        0.48 0.92</span>
<span class="err">## Proportion Explained  0.52 0.48</span>
<span class="err">## Cumulative Proportion 0.52 1.00</span>
<span class="err">## </span>
<span class="err">## Mean item complexity =  1.1</span>
<span class="err">## Test of the hypothesis that 2 factors are sufficient.</span>
<span class="err">## </span>
<span class="err">## The degrees of freedom for the null model are  6  and the objective function was  4.19 with Chi Square of  187.92</span>
<span class="err">## The degrees of freedom for the model are -1  and the objective function was  0.06 </span>
<span class="err">## </span>
<span class="err">## The root mean square of the residuals (RMSR) is  0.01 </span>
<span class="err">## The df corrected root mean square of the residuals is  NA </span>
<span class="err">## </span>
<span class="err">## The harmonic number of observations is  48 with the empirical chi square  0.03  with prob &lt;  NA </span>
<span class="err">## The total number of observations was  48  with Likelihood Chi Square =  2.75  with prob &lt;  NA </span>
<span class="err">## </span>
<span class="err">## Tucker Lewis Index of factoring reliability =  1.128</span>
<span class="err">## Fit based upon off diagonal values = 1</span>
<span class="err">## Measures of factor score adequacy             </span>
<span class="err">##                                                    PA1  PA2</span>
<span class="err">## Correlation of (regression) scores with factors   0.98 0.96</span>
<span class="err">## Multiple R square of scores with factors          0.97 0.93</span>
<span class="err">## Minimum correlation of possible factor scores     0.93 0.86</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">root.cor.pa</span> <span class="o">&lt;-</span> <span class="nf">principal</span><span class="p">(</span><span class="n">root</span><span class="p">[,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="p">],</span> <span class="n">nfactors</span> <span class="o">=</span> <span class="m">2</span><span class="p">,</span> <span class="n">rotate</span> <span class="o">=</span> <span class="s">&#39;varimax&#39;</span><span class="p">)</span>
<span class="n">root.cor.pa</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## Principal Components Analysis</span>
<span class="err">## Call: principal(r = root[, 2:5], nfactors = 2, rotate = &quot;varimax&quot;)</span>
<span class="err">## Standardized loadings (pattern matrix) based upon correlation matrix</span>
<span class="err">##                               RC1  RC2   h2    u2 com</span>
<span class="err">## Trunk.Girth.4.Years          0.16 0.96 0.95 0.051 1.1</span>
<span class="err">## Ext.Growth.4.Years           0.28 0.93 0.94 0.061 1.2</span>
<span class="err">## Trunk.Girth.15.Years         0.94 0.29 0.97 0.027 1.2</span>
<span class="err">## Weight.Above.Ground.15.Years 0.97 0.19 0.98 0.022 1.1</span>
<span class="err">## </span>
<span class="err">##                        RC1  RC2</span>
<span class="err">## SS loadings           1.94 1.90</span>
<span class="err">## Proportion Var        0.48 0.48</span>
<span class="err">## Cumulative Var        0.48 0.96</span>
<span class="err">## Proportion Explained  0.50 0.50</span>
<span class="err">## Cumulative Proportion 0.50 1.00</span>
<span class="err">## </span>
<span class="err">## Mean item complexity =  1.1</span>
<span class="err">## Test of the hypothesis that 2 components are sufficient.</span>
<span class="err">## </span>
<span class="err">## The root mean square of the residuals (RMSR) is  0.03 </span>
<span class="err">##  with the empirical chi square  0.39  with prob &lt;  NA </span>
<span class="err">## </span>
<span class="err">## Fit based upon off diagonal values = 1</span>
</pre></div>


<p>Similar to the previous case with the non-iterated method, the principal
component approach resulted in factors that loaded higher on their
respective variables and represents slightly more cumulative variance of
the data. The difference between the methods is rather small, yet one
would be inclined to use the principal component method results.</p>
<h2>References</h2>
<p><a href="https://amzn.to/39gsldt">Rencher, A. C. (2002). Methods of multivariate analysis. New York: J. Wiley.</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

                <h3 style="margin-top: 2em;">Related Posts</h3>

                    <ul class="blank">
                        <li><a href="https://aaronschlegel.me/factor-analysis-principal-component-method-r-part-two.html">Factor Analysis with the Principal Component Method and R Part Two</a></li>
                        <li><a href="https://aaronschlegel.me/factor-analysis-principal-component-method-r.html">Factor Analysis with the Principal Component Method and R</a></li>
                        <li><a href="https://aaronschlegel.me/quadratic-discriminant-analysis-several-groups.html">Quadratic Discriminant Analysis of Several Groups</a></li>
                        <li><a href="https://aaronschlegel.me/quadratic-discriminant-analysis-two-groups.html">Quadratic Discriminant Analysis of Two Groups</a></li>
                        <li><a href="https://aaronschlegel.me/linear-discriminant-analysis-classification-several-groups.html">Linear Discriminant Analysis for the Classification of Several Groups</a></li>
                    </ul>
            </div><!-- /.entry-content -->



        </div><!-- /.eleven.columns -->

<div class="three columns">

        <h3>Categories</h3>
        <ul class="blank">
                <li><a href="https://aaronschlegel.me/category/analysis.html">Analysis</a></li>
                <li><a href="https://aaronschlegel.me/category/calculus.html">Calculus</a></li>
                <li><a href="https://aaronschlegel.me/category/finance.html">Finance</a></li>
                <li><a href="https://aaronschlegel.me/category/linear-algebra.html">Linear Algebra</a></li>
                <li><a href="https://aaronschlegel.me/category/machine-learning.html">Machine Learning</a></li>
                <li><a href="https://aaronschlegel.me/category/nasapy.html">nasapy</a></li>
                <li><a href="https://aaronschlegel.me/category/petpy.html">petpy</a></li>
                <li><a href="https://aaronschlegel.me/category/poetpy.html">poetpy</a></li>
                <li><a href="https://aaronschlegel.me/category/python.html">Python</a></li>
                <li><a href="https://aaronschlegel.me/category/r.html">R</a></li>
                <li><a href="https://aaronschlegel.me/category/sql.html">SQL</a></li>
                <li><a href="https://aaronschlegel.me/category/statistics.html">Statistics</a></li>
        </ul>


    <h3>Recent Posts</h3>

    <ul class="blank">
            <li>
              <a href="https://aaronschlegel.me/van-der-waerdens-normal-scores-test.html">Van der Waerden's Normal Scores Test</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/generalized-black-scholes-formula-european-options.html">The Generalized Black-Scholes Formula for European Options</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/get-all-nasa-astronomy-pictures-day-2019.html">Get All NASA Astronomy Pictures of the Day from 2019</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/analyzing-next-decade-earth-close-approaching-objects-nasapy.html">Analyzing the Next Decade of Earth Close-Approaching Objects with nasapy</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/plot-earth-fireball-impacts-nasapy-pandas-folium.html">Plot Earth Fireball Impacts with nasapy, pandas and folium</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/integration-by-parts.html">Integration by Parts</a>
            </li>
    </ul>

        <nav class="widget">
          <h3>Blogroll</h3>
          <ul class="blank">
            <li>
                <a href="https://www.r-bloggers.com">R-Bloggers</a>
            </li>
          </ul>
        </nav>

</div> </div><!-- /.row -->


</section>



       </div><!-- /.row -->
    </div><!-- /.container -->
       <div class="container.nopad bg">
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                    which takes great advantage of <a href="http://python.org">Python</a>.
                    <br />
                    Based on the <a target="_blank" href="http://gumbyframework.com">Gumby Framework</a>
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">

                <li><div class="btn primary"><a href="https://github.com/aschleg" target="_blank">Github</a></div></li>

                <li><div class="btn twitter"><a href="http://www.twitter.com/Aaron_Schlegel" target="_blank">Twitter</a></div></li>


                <li><div class="btn danger"><a href="https://plus.google.com/u/0/102881569650657098667" target="_blank">Google+</a></div></li>

              </ul>
            </div>
          </div>
        </footer>

    </div>


  <script src="https://aaronschlegel.me/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="https://aaronschlegel.me/theme/js/libs/gumby.min.js"></script>
  <script src="https://aaronschlegel.me/theme/js/plugins.js"></script>
</body>
</html>