<!DOCTYPE html>
<html lang="english">
<head>

        <title>Linear Discriminant Analysis for the Classification of Several Groups</title>
        <meta charset="utf-8" />
        <link href="https://aaronschlegel.me/feed/all.xml" type="application/atom+xml" rel="alternate" title="Aaron Schlegel's Notebook of Interesting Things Full Atom Feed" />
        <link href="https://aaronschlegel.me/feed/linear-algebra.xml" type="application/atom+xml" rel="alternate" title="Aaron Schlegel's Notebook of Interesting Things Categories Atom Feed" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">
        <meta name="description" content="Similar to the two-group linear discriminant analysis for classification case, LDA for classification into several groups seeks to find the mean vector that the new observation \(y\) is closest to and assign \(y\) accordingly using a distance function. The several group case also assumes equal covariance matrices amongst the groups (\(\Sigma_1 = \Sigma_2 = \cdots = \Sigma_k\)). if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = "center", indent = "0em", linebreak = "false"; if (false) { align = (screen.width" />
        <meta property="og:site_name" content="Aaron Schlegel's Notebook of Interesting Things" />
        <meta property="og:type" content="article" />
        <meta property="og:title" content="Linear Discriminant Analysis for the Classification of Several Groups" />
        <meta property="og:url" content="https://aaronschlegel.me" />
        <meta property="og:description" content="" />
        <meta property="article:published_time" content="2018-08-28 00:00:00-07:00" />
        <meta property="article:modified_time" content="" />
        <meta name="twitter:site" content="@Aaron_Schlegel" />
        <meta name="twitter:creator" content="@Aaron_Schlegel" />
        <meta name="twitter:card" content="Similar to the two-group linear discriminant analysis for classification case, LDA for classification into several groups seeks to find the mean vector that the new observation \(y\) is closest to and assign \(y\) accordingly using a distance function. The several group case also assumes equal covariance matrices amongst the groups (\(\Sigma_1 = \Sigma_2 = \cdots = \Sigma_k\)). if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = "center", indent = "0em", linebreak = "false"; if (false) { align = (screen.width" />
        <meta name="twitter:card" content="The Blog and Notebooks of Aaron Schlegel" />

        <link rel="stylesheet" type="text/css" href="https://aaronschlegel.me/theme/css/styles.min.css" />
        <link rel="canonical" href="https://aaronschlegel.me/linear-discriminant-analysis-classification-several-groups.html" />

        <script src="https://aaronschlegel.me/theme/js/libs/modernizr-2.6.2.min.js"></script>

              <script>
                (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

                ga('create', 'UA-48350829-2', 'aaronschlegel.me');
                ga('send', 'pageview');

              </script>


</head>

<body id="index" class="home">
    <div class="container">
        <div class="row">

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>

              <ul class="columns-right">
                <li><a href="https://aaronschlegel.me/">Home</a></li>

                <li><a href="https://aaronschlegel.me/pages/projects.html">Projects</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">
            <header>
              <h2 class="entry-title">
                <a href="https://aaronschlegel.me/linear-discriminant-analysis-classification-several-groups.html" rel="bookmark"
                   title="Permalink to Linear Discriminant Analysis for the Classification of Several Groups">Linear Discriminant Analysis for the Classification of Several Groups</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2018-08-28T00:00:00-07:00">
                Tue 28 August 2018
              </abbr>
              <address class="vcard author">By 
                <a class="url fn" href="https://aaronschlegel.me/author/aaron-schlegel.html"> Aaron Schlegel</a>
              </address>
            </footer><!-- /.post-info -->
            <div class="entry-content">
                <p>Similar to the two-group linear discriminant analysis for classification case, LDA for classification into several groups seeks to find the mean vector that the new observation <span class="math">\(y\)</span> is closest to and assign <span class="math">\(y\)</span> accordingly using a distance function. The several group case also assumes equal covariance matrices amongst the groups (<span class="math">\(\Sigma_1 = \Sigma_2 = \cdots = \Sigma_k\)</span>).</p>
<h2>LDA for Classification into Several Groups</h2>
<p>As in the two-group case, the common population covariance matrix S_{p1}$ must be estimated:</p>
<div class="math">$$ S_{p1} = \frac{1}{N - k} \sum_{i=1}^k (n_i - 1)S_i = \frac{E}{N - k} $$</div>
<p>Where <span class="math">\(n_i\)</span> and <span class="math">\(S_i\)</span> are the sample size and covariance matrix of the <span class="math">\(i^{th}\)</span> group, <span class="math">\(E\)</span> is the error matrix as seen in one-way MANOVA and <span class="math">\(N\)</span> is the total sample size. The observation vector to be classified <span class="math">\(y\)</span> is then compared to each mean vector <span class="math">\(\bar{y}_i, i = 1, 2, \cdots, k\)</span> using the following distance function:</p>
<div class="math">$$ D_i^2(y) = (y - \bar{y}_i)'S_{p1}^{-1}(y - \bar{y}_i) $$</div>
<p>The above distance function is then expanded, and the resulting unnecessary terms are dropped to obtain a linear classification function for several groups denoted by <span class="math">\(L_i(y)\)</span>.</p>
<div class="math">$$ L_i(y) = \bar{y}_i S_{p1}^{-1}y - \frac{1}{2} \bar{y}_i S_{p1}^{-1}\bar{y}_i \qquad i = 1, 2, \cdots, k $$</div>
<p>Thus the observation vector <span class="math">\(y\)</span> is assigned to the group that maximizes <span class="math">\(L_i(y)\)</span>.</p>
<h2>LDA for Several Group Classification in R</h2>
<p>We will classify observations from the rootstock data to demonstrate LDA for classification into several groups. The rootstock data were obtained from the <a href="ftp://ftp.wiley.com">companion FTP site</a> of the book Methods of Multivariate Analysis by Alvin Rencher.</p>
<div class="highlight"><pre><span></span><span class="n">root</span> <span class="o">&lt;-</span> <span class="nf">read.table</span><span class="p">(</span><span class="s">&#39;ROOT.DAT&#39;</span><span class="p">,</span> <span class="n">col.names</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Tree.Number&#39;</span><span class="p">,</span> <span class="s">&#39;Trunk.Girth.4.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Ext.Growth.4.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Trunk.Girth.15.Years&#39;</span><span class="p">,</span> <span class="s">&#39;Weight.Above.Ground.15.Years&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nf">head</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##   Tree.Number Trunk.Girth.4.Years Ext.Growth.4.Years Trunk.Girth.15.Years</span>
<span class="err">## 1           1                1.11              2.569                 3.58</span>
<span class="err">## 2           1                1.19              2.928                 3.75</span>
<span class="err">## 3           1                1.09              2.865                 3.93</span>
<span class="err">## 4           1                1.25              3.844                 3.94</span>
<span class="err">## 5           1                1.11              3.027                 3.60</span>
<span class="err">## 6           1                1.08              2.336                 3.51</span>
<span class="err">##   Weight.Above.Ground.15.Years</span>
<span class="err">## 1                        0.760</span>
<span class="err">## 2                        0.821</span>
<span class="err">## 3                        0.928</span>
<span class="err">## 4                        1.009</span>
<span class="err">## 5                        0.766</span>
<span class="err">## 6                        0.726</span>
</pre></div>


<p>Split the data by the groups and calculate the group mean vectors.</p>
<div class="highlight"><pre><span></span><span class="n">root.group</span> <span class="o">&lt;-</span> <span class="nf">split</span><span class="p">(</span><span class="n">root[</span><span class="p">,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="n">]</span><span class="p">,</span> <span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">)</span>

<span class="n">root.means</span> <span class="o">&lt;-</span> <span class="nf">sapply</span><span class="p">(</span><span class="n">root.group</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="nf">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>
<span class="p">},</span> <span class="n">simplify</span> <span class="o">=</span> <span class="s">&#39;data.frame&#39;</span><span class="p">)</span>
</pre></div>


<p>Compute the error matrix <span class="math">\(E\)</span> and the pooled sample covariance matrix <span class="math">\(S_{p1}\)</span>.</p>
<div class="highlight"><pre><span></span><span class="n">E</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">nrow</span> <span class="o">=</span> <span class="m">4</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">4</span><span class="p">)</span>
<span class="nf">for </span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="nf">dim</span><span class="p">(</span><span class="n">E</span><span class="p">)</span><span class="n">[1]</span><span class="p">)</span> <span class="p">{</span>
  <span class="nf">for </span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">b</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">()</span> 
    <span class="nf">for </span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="n">root.group</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">a</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">((</span><span class="n">k[</span><span class="p">,</span><span class="n">i]</span> <span class="o">-</span> <span class="nf">mean</span><span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">i]</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">j]</span> <span class="o">-</span> <span class="nf">mean</span><span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">j]</span><span class="p">)))</span>
      <span class="n">b</span> <span class="o">&lt;-</span> <span class="nf">append</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">E[i</span><span class="p">,</span><span class="n">j]</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="n">E[j</span><span class="p">,</span><span class="n">i]</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">N</span> <span class="o">&lt;-</span> <span class="nf">dim</span><span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="n">[1]</span>
<span class="n">k</span> <span class="o">&lt;-</span> <span class="nf">length</span><span class="p">(</span><span class="nf">unique</span><span class="p">(</span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">))</span>
<span class="n">sp1</span> <span class="o">&lt;-</span> <span class="n">E</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">k</span><span class="p">)</span>
</pre></div>


<p><span class="math">\(L_i(y)\)</span> is then computed for each observation in the rootstock dataset.</p>
<div class="highlight"><pre><span></span><span class="n">li.y</span> <span class="o">&lt;-</span> <span class="nf">apply</span><span class="p">(</span><span class="n">root[</span><span class="p">,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="n">]</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
  <span class="nf">sapply</span><span class="p">(</span><span class="n">root.group</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">y.bar</span> <span class="o">&lt;-</span> <span class="nf">as.numeric</span><span class="p">(</span><span class="nf">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="n">mean</span><span class="p">))</span>
    <span class="n">y.bar</span> <span class="o">%*%</span> <span class="nf">solve</span><span class="p">(</span><span class="n">sp1</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">y</span> <span class="o">-</span> <span class="m">.5</span> <span class="o">*</span> <span class="n">y.bar</span> <span class="o">%*%</span> <span class="nf">solve</span><span class="p">(</span><span class="n">sp1</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">y.bar</span>
  <span class="p">},</span> <span class="n">simplify</span> <span class="o">=</span> <span class="s">&#39;data.frame&#39;</span><span class="p">)</span>
<span class="p">})</span>
</pre></div>


<p>The last step is to find the group that maximized the value of <span class="math">\(L_i(y)\)</span> for each observation.</p>
<div class="highlight"><pre><span></span><span class="n">root.prediction</span> <span class="o">&lt;-</span> <span class="nf">apply</span><span class="p">(</span><span class="nf">t</span><span class="p">(</span><span class="n">li.y</span><span class="p">),</span> <span class="m">1</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="nf">which</span><span class="p">(</span><span class="n">x</span><span class="o">==</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="p">})</span>
</pre></div>


<p>Print the classifications and the actual groups for comparison as well as a confusion matrix.</p>
<div class="highlight"><pre><span></span><span class="n">root.prediction</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##  [1] 1 1 6 1 1 6 4 1 5 4 3 2 5 2 3 2 4 3 5 3 3 3 3 3 1 3 1 4 1 4 4 4 5 3 2</span>
<span class="err">## [36] 5 6 2 5 2 6 6 6 5 6 1 1 5</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##  [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 5 5 5</span>
<span class="err">## [36] 5 5 5 5 5 6 6 6 6 6 6 6 6</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">,</span> <span class="n">root.prediction</span><span class="p">,</span> <span class="n">dnn</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Actual Group&#39;</span><span class="p">,</span><span class="s">&#39;Predicted Group&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##             Predicted Group</span>
<span class="err">## Actual Group 1 2 3 4 5 6</span>
<span class="err">##            1 5 0 0 1 0 2</span>
<span class="err">##            2 0 3 2 1 2 0</span>
<span class="err">##            3 0 0 6 1 1 0</span>
<span class="err">##            4 3 0 1 4 0 0</span>
<span class="err">##            5 0 3 1 0 3 1</span>
<span class="err">##            6 2 0 0 0 2 4</span>
</pre></div>


<p>It appears the classification function had decent success classifying observations in groups 1, 3, 4 and six but was less accurate in identifying observations belonging to the other groups.</p>
<p>Count the number of accurate classifications.</p>
<div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">root.prediction</span> <span class="o">==</span> <span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## [1] 25</span>
</pre></div>


<p>25 accurate classifications out of a total sample size of 48 give an error rate of 48%. We will see later in this post if cross-validation can improve the misclassification rate.</p>
<p>The function <code>lda()</code> available in the <a href="https://cran.r-project.org/web/packages/MASS/index.html">MASS package</a> also performs classification into several groups.</p>
<div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">MASS</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">root.lda</span> <span class="o">&lt;-</span> <span class="nf">lda</span><span class="p">(</span><span class="n">Tree.Number</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">root</span><span class="p">)</span>
<span class="n">lda.pred</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">root.lda</span><span class="p">)</span><span class="o">$</span><span class="n">class</span>
<span class="nf">table</span><span class="p">(</span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">,</span> <span class="n">lda.pred</span><span class="p">,</span> <span class="n">dnn</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Actual Group&#39;</span><span class="p">,</span><span class="s">&#39;Predicted Group&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##             Predicted Group</span>
<span class="err">## Actual Group 1 2 3 4 5 6</span>
<span class="err">##            1 5 0 0 1 0 2</span>
<span class="err">##            2 0 3 2 1 2 0</span>
<span class="err">##            3 0 0 6 1 1 0</span>
<span class="err">##            4 3 0 1 4 0 0</span>
<span class="err">##            5 0 3 1 0 3 1</span>
<span class="err">##            6 2 0 0 0 2 4</span>
</pre></div>


<h2>Cross-Validation of Classifications</h2>
<p><a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#Leave-one-out_cross-validation">Leave-one-out cross-validation</a> is employed on the rootstock dataset in the following code in hopes of finding a more accurate, as well as realistic, model for classifying new and unknown observations. Leave-one-out cross-validation is performed by using all but one of the sample observation vectors to determine the classification function and then using that classification function to predict the omitted observation's group membership. The procedure is repeated for each observation so that each is classified by a function of the other observations.</p>
<div class="highlight"><pre><span></span><span class="n">cv.prediction</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">()</span>

<span class="nf">for </span><span class="p">(</span><span class="n">r</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="n">N</span><span class="p">)</span> <span class="p">{</span>

  <span class="n">holdout</span> <span class="o">&lt;-</span> <span class="n">root[</span><span class="o">-</span><span class="n">r</span><span class="p">,</span><span class="n">]</span>
  <span class="n">root.group</span> <span class="o">&lt;-</span> <span class="nf">split</span><span class="p">(</span><span class="n">holdout[</span><span class="p">,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="n">]</span><span class="p">,</span> <span class="n">holdout</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">)</span>

  <span class="n">E</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">nrow</span> <span class="o">=</span> <span class="m">4</span><span class="p">,</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">4</span><span class="p">)</span>
  <span class="nf">for </span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="nf">dim</span><span class="p">(</span><span class="n">E</span><span class="p">)</span><span class="n">[1]</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">for </span><span class="p">(</span><span class="n">j</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">b</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">()</span> 
      <span class="nf">for </span><span class="p">(</span><span class="n">k</span> <span class="n">in</span> <span class="n">root.group</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">a</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">((</span><span class="n">k[</span><span class="p">,</span><span class="n">i]</span> <span class="o">-</span> <span class="nf">mean</span><span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">i]</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">j]</span> <span class="o">-</span> <span class="nf">mean</span><span class="p">(</span><span class="n">k[</span><span class="p">,</span><span class="n">j]</span><span class="p">)))</span>
        <span class="n">b</span> <span class="o">&lt;-</span> <span class="nf">append</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
      <span class="p">}</span>
      <span class="n">E[i</span><span class="p">,</span><span class="n">j]</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
      <span class="n">E[j</span><span class="p">,</span><span class="n">i]</span> <span class="o">&lt;-</span> <span class="nf">sum</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">sp1</span> <span class="o">&lt;-</span> <span class="n">E</span> <span class="o">/</span> <span class="p">(</span><span class="nf">dim</span><span class="p">(</span><span class="n">holdout</span><span class="p">)</span><span class="n">[1]</span> <span class="o">-</span> <span class="nf">length</span><span class="p">(</span><span class="nf">unique</span><span class="p">(</span><span class="n">holdout</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">)))</span>

  <span class="n">li</span> <span class="o">&lt;-</span> <span class="nf">sapply</span><span class="p">(</span><span class="n">root.group</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">y.bar</span> <span class="o">&lt;-</span> <span class="nf">as.numeric</span><span class="p">(</span><span class="nf">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="n">mean</span><span class="p">))</span>
    <span class="n">y.bar</span> <span class="o">%*%</span> <span class="nf">solve</span><span class="p">(</span><span class="n">sp1</span><span class="p">)</span> <span class="o">%*%</span> <span class="nf">as.numeric</span><span class="p">(</span><span class="n">root[r</span><span class="p">,</span><span class="m">2</span><span class="o">:</span><span class="m">5</span><span class="n">]</span><span class="p">)</span> <span class="o">-</span> <span class="m">.5</span> <span class="o">*</span> <span class="n">y.bar</span> <span class="o">%*%</span> <span class="nf">solve</span><span class="p">(</span><span class="n">sp1</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">y.bar</span>
  <span class="p">},</span> <span class="n">simplify</span> <span class="o">=</span> <span class="s">&#39;data.frame&#39;</span><span class="p">)</span>

  <span class="n">li.y</span> <span class="o">&lt;-</span> <span class="nf">apply</span><span class="p">(</span><span class="nf">t</span><span class="p">(</span><span class="n">li</span><span class="p">),</span> <span class="m">1</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="p">{</span>
    <span class="nf">which</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="nf">max</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
  <span class="p">})</span>

  <span class="n">cv.prediction</span> <span class="o">&lt;-</span> <span class="nf">append</span><span class="p">(</span><span class="n">cv.prediction</span><span class="p">,</span> <span class="n">li.y</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">,</span> <span class="n">cv.prediction</span><span class="p">,</span> <span class="n">dnn</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Actual Group&#39;</span><span class="p">,</span><span class="s">&#39;Predicted Group&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##             Predicted Group</span>
<span class="err">## Actual Group 1 2 3 4 5 6</span>
<span class="err">##            1 5 0 0 1 0 2</span>
<span class="err">##            2 0 2 2 1 3 0</span>
<span class="err">##            3 0 0 6 1 1 0</span>
<span class="err">##            4 4 0 1 3 0 0</span>
<span class="err">##            5 0 3 2 0 2 1</span>
<span class="err">##            6 3 0 0 0 2 3</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nf">sum</span><span class="p">(</span><span class="n">cv.prediction</span> <span class="o">==</span> <span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">## [1] 21</span>
</pre></div>


<p>The cross-validated results have a higher misclassification rate of 56%, which could be expected given the total sample size may yield a more optimistic and biased classification model without cross-validation. Though the misclassification rate may seem high in absolute terms, it is still much more accurate than simply guessing the observation's group membership, which would have an error rate of 83% <span class="math">\((1 - \frac{1}{6})\)</span>.</p>
<p>The <code>lda()</code> function also performs cross-validation with the <code>CV</code> argument set to <code>TRUE</code>.</p>
<div class="highlight"><pre><span></span><span class="n">root.cv</span> <span class="o">&lt;-</span> <span class="nf">lda</span><span class="p">(</span><span class="n">Tree.Number</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">CV</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">root</span><span class="p">)</span>
<span class="n">root.cv</span><span class="o">$</span><span class="n">class</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##  [1] 1 1 6 1 1 6 4 1 5 4 3 2 5 5 3 2 4 3 5 3 3 3 3 3 1 3 1 4 1 4 4 1 5 3 2</span>
<span class="err">## [36] 5 6 2 3 2 1 6 6 5 6 1 1 5</span>
<span class="err">## Levels: 1 2 3 4 5 6</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nf">table</span><span class="p">(</span><span class="n">root</span><span class="o">$</span><span class="n">Tree.Number</span><span class="p">,</span> <span class="n">root.cv</span><span class="o">$</span><span class="n">class</span><span class="p">,</span> <span class="n">dnn</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#39;Actual Group&#39;</span><span class="p">,</span><span class="s">&#39;Predicted Group&#39;</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">##             Predicted Group</span>
<span class="err">## Actual Group 1 2 3 4 5 6</span>
<span class="err">##            1 5 0 0 1 0 2</span>
<span class="err">##            2 0 2 2 1 3 0</span>
<span class="err">##            3 0 0 6 1 1 0</span>
<span class="err">##            4 4 0 1 3 0 0</span>
<span class="err">##            5 0 3 2 0 2 1</span>
<span class="err">##            6 3 0 0 0 2 3</span>
</pre></div>


<h2>References</h2>
<p><a href="https://amzn.to/39gsldt">Rencher, A. C. (2002). Methods of multivariate analysis. New York: J. Wiley.</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

                <h3 style="margin-top: 2em;">Related Posts</h3>

                    <ul class="blank">
                        <li><a href="https://aaronschlegel.me/linear-discriminant-analysis-classification-two-groups.html">Linear Discriminant Analysis for the Classification of Two Groups</a></li>
                        <li><a href="https://aaronschlegel.me/discriminant-analysis-group-separation.html">Discriminant Analysis for Group Separation</a></li>
                        <li><a href="https://aaronschlegel.me/quadratic-discriminant-analysis-several-groups.html">Quadratic Discriminant Analysis of Several Groups</a></li>
                        <li><a href="https://aaronschlegel.me/quadratic-discriminant-analysis-two-groups.html">Quadratic Discriminant Analysis of Two Groups</a></li>
                        <li><a href="https://aaronschlegel.me/discriminant-analysis-several-groups.html">Discriminant Analysis of Several Groups</a></li>
                    </ul>
            </div><!-- /.entry-content -->



        </div><!-- /.eleven.columns -->

<div class="three columns">

        <h3>Categories</h3>
        <ul class="blank">
                <li><a href="https://aaronschlegel.me/category/analysis.html">Analysis</a></li>
                <li><a href="https://aaronschlegel.me/category/calculus.html">Calculus</a></li>
                <li><a href="https://aaronschlegel.me/category/finance.html">Finance</a></li>
                <li><a href="https://aaronschlegel.me/category/linear-algebra.html">Linear Algebra</a></li>
                <li><a href="https://aaronschlegel.me/category/machine-learning.html">Machine Learning</a></li>
                <li><a href="https://aaronschlegel.me/category/nasapy.html">nasapy</a></li>
                <li><a href="https://aaronschlegel.me/category/petpy.html">petpy</a></li>
                <li><a href="https://aaronschlegel.me/category/poetpy.html">poetpy</a></li>
                <li><a href="https://aaronschlegel.me/category/python.html">Python</a></li>
                <li><a href="https://aaronschlegel.me/category/r.html">R</a></li>
                <li><a href="https://aaronschlegel.me/category/sql.html">SQL</a></li>
                <li><a href="https://aaronschlegel.me/category/statistics.html">Statistics</a></li>
        </ul>


    <h3>Recent Posts</h3>

    <ul class="blank">
            <li>
              <a href="https://aaronschlegel.me/generalized-black-scholes-formula-european-options.html">The Generalized Black-Scholes Formula for European Options</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/get-all-nasa-astronomy-pictures-day-2019.html">Get All NASA Astronomy Pictures of the Day from 2019</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/analyzing-next-decade-earth-close-approaching-objects-nasapy.html">Analyzing the Next Decade of Earth Close-Approaching Objects with nasapy</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/plot-earth-fireball-impacts-nasapy-pandas-folium.html">Plot Earth Fireball Impacts with nasapy, pandas and folium</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/integration-by-parts.html">Integration by Parts</a>
            </li>
            <li>
              <a href="https://aaronschlegel.me/lhospital-rule-calculating-limits-indeterminate-forms.html">L'Hospital's Rule for Calculating Limits and Indeterminate Forms</a>
            </li>
    </ul>

        <nav class="widget">
          <h3>Blogroll</h3>
          <ul class="blank">
            <li>
                <a href="https://www.r-bloggers.com">R-Bloggers</a>
            </li>
          </ul>
        </nav>

</div> </div><!-- /.row -->


</section>



       </div><!-- /.row -->
    </div><!-- /.container -->
       <div class="container.nopad bg">
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                    which takes great advantage of <a href="http://python.org">Python</a>.
                    <br />
                    Based on the <a target="_blank" href="http://gumbyframework.com">Gumby Framework</a>
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">

                <li><div class="btn primary"><a href="https://github.com/aschleg" target="_blank">Github</a></div></li>

                <li><div class="btn twitter"><a href="http://www.twitter.com/Aaron_Schlegel" target="_blank">Twitter</a></div></li>


                <li><div class="btn danger"><a href="https://plus.google.com/u/0/102881569650657098667" target="_blank">Google+</a></div></li>

              </ul>
            </div>
          </div>
        </footer>

    </div>


  <script src="https://aaronschlegel.me/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="https://aaronschlegel.me/theme/js/libs/gumby.min.js"></script>
  <script src="https://aaronschlegel.me/theme/js/plugins.js"></script>
</body>
</html>